{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9903823,"sourceType":"datasetVersion","datasetId":6084281}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sqlite3\nimport pandas as pd\nfrom typing import Union, List, Dict, Any\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\nimport re\n\nclass SQLAgent:\n    \"\"\"\n    Role: Generate SQL queries from natural language questions using LLM\n    \"\"\"\n    def __init__(self, model_name: str = \"huyhoangt2201/llama-3.2-1b-chat-sql3-merged\"):\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n        self.context = \"\"\"\n        You are an SQL query assistant. Based on the table information below, generate an SQL query to retrieve the relevant information for the user. If the user's question is unrelated to the table, respond naturally in user's language.\n\n        The jidouka table contains the following columns:\n        id: Row identifier (int)\n        tên_cải_tiến: Name of the improvement (str) \n        loại_hình_công_việc: Type of work that the improvement is intended to enhance (str)\n        công_cụ: Tool used to achieve the improvement (str)\n        mô_tả: Detailed description of the improvement (str)\n        sản_phẩm: Output product of the improvement (str)\n        tác_giả: Contributor or creator of the improvement (str)\n        bộ_phận: Department of the author (str)\n        số_giờ: Number of hours saved (int)\n        số_công_việc_áp_dụng: Number of tasks supported (int)\n        thời_điểm_ra_mắt: Launch date of the tool (str)\n        thông_tin_thêm: Link to additional documentation (str)\n\n        Return only the SQL query without any additional text. If the question is not related to the database, return \"NOT_SQL_QUERY: \" followed by your response.\n        \"\"\"\n        \n    def generate_query(self, question: str) -> str:\n        \"\"\"Generate SQL query from natural language question\"\"\"\n        messages = [\n            {'role': 'system', 'content': self.context},\n            {'role': 'user', 'content': question}\n        ]\n        \n        # Prepare tokenizer\n        eot = \"<|eot_id|>\"\n        eot_id = self.tokenizer.convert_tokens_to_ids(eot)\n        self.tokenizer.pad_token = eot\n        self.tokenizer.pad_token_id = eot_id\n        \n        # Generate response\n        tokenized_chat = self.tokenizer.apply_chat_template(\n            messages, \n            tokenize=False, \n            add_generation_prompt=True\n        )\n        \n        inputs = self.tokenizer(\n            tokenized_chat, \n            return_tensors='pt', \n            padding=True, \n            truncation=True\n        )\n        \n        outputs = self.model.generate(\n            inputs['input_ids'],\n            attention_mask=inputs['attention_mask'],\n            pad_token_id=self.tokenizer.eos_token_id,\n            max_new_tokens=256,\n            temperature=0.7,\n            do_sample=True\n        )\n        \n        response = self.tokenizer.decode(outputs[0])\n        response = response.split('<|start_header_id|>assistant<|end_header_id|>')[1].strip()[:-10]\n        \n        return response.strip()\n\nclass ExecuteQueryAgent:\n    \"\"\"\n    Role: Execute SQL queries and handle responses\n    \"\"\"\n    def __init__(self, db_path: str):\n        self.db_path = db_path\n        \n    def is_valid_sql_query(self, query: str) -> bool:\n        \"\"\"Check if the string is a valid SQL query\"\"\"\n        if query.startswith(\"NOT_SQL_QUERY:\"):\n            return False\n            \n        # Basic SQL validation\n        sql_keywords = [\"SELECT\", \"FROM\", \"WHERE\", \"GROUP BY\", \"ORDER BY\", \"HAVING\", \"JOIN\"]\n        query_upper = query.upper()\n        return any(keyword in query_upper for keyword in sql_keywords)\n    \n    def execute_query(self, query: str) -> Union[List[Dict[str, Any]], str]:\n        \"\"\"Execute SQL query and return results\"\"\"\n        if not self.is_valid_sql_query(query):\n            if query.startswith(\"NOT_SQL_QUERY:\"):\n                return query[13:].strip()  # Return the natural language response\n            return []\n            \n        try:\n            with sqlite3.connect(self.db_path) as conn:\n                df = pd.read_sql_query(query, conn)\n                return df.to_dict('records')\n        except Exception as e:\n            print(f\"Error executing query: {e}\")\n            return []\n\nclass LLMAgent:\n    \"\"\"\n    Role: Generate natural language responses from query results\n    \"\"\"\n    def __init__(self, model_name: str = \"huyhoangt2201/llama-3.2-1b-chat-sql3-merged\"):\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n        \n    def generate_response(self, question: str, data_points: Union[List[Dict[str, Any]], str]) -> str:\n        \"\"\"Generate natural language response based on query results\"\"\"\n        \n        # If data_points is already a string (natural language response)\n        if isinstance(data_points, str):\n            return data_points\n            \n        # Handle empty results\n        if not data_points:\n            return \"Tôi không tìm thấy dữ liệu phù hợp với câu hỏi của bạn. Vui lòng thử lại với câu hỏi khác.\"\n        \n        system_prompt = \"\"\"You are an assistant who answers questions based on given data points.\n        Requirements:\n        - Answer in the same language as the user's question\n        - Be concise but informative\n        - If the data points are empty, answer based on general knowledge\n        - Format numbers and dates appropriately\n        \"\"\"\n        \n        user_prompt = f\"Question: {question}\\nData points: {str(data_points)}\"\n        \n        messages = [\n            {'role': 'system', 'content': system_prompt},\n            {'role': 'user', 'content': user_prompt}\n        ]\n        \n        # Setup tokenizer\n        eot = \"<|eot_id|>\"\n        eot_id = self.tokenizer.convert_tokens_to_ids(eot)\n        self.tokenizer.pad_token = eot\n        self.tokenizer.pad_token_id = eot_id\n        \n        # Generate response\n        tokenized_chat = self.tokenizer.apply_chat_template(\n            messages, \n            tokenize=False, \n            add_generation_prompt=True\n        )\n        \n        inputs = self.tokenizer(\n            tokenized_chat, \n            return_tensors='pt', \n            padding=True, \n            truncation=True\n        )\n        \n        outputs = self.model.generate(\n            inputs['input_ids'],\n            attention_mask=inputs['attention_mask'],\n            pad_token_id=self.tokenizer.eos_token_id,\n            max_new_tokens=256,\n            temperature=0.7\n        )\n        \n        response = self.tokenizer.decode(outputs[0])\n        response = response.split('<|start_header_id|>assistant<|end_header_id|>')[1].strip()[:-10]\n        \n        return response.strip()\n\nclass MultiAgentModel:\n    \"\"\"\n    Main class that coordinates all agents\n    \"\"\"\n    def __init__(self, db_path: str, model_name: str = \"huyhoangt2201/llama-3.2-1b-chat-sql3-merged\"):\n        self.sql_agent = SQLAgent(model_name)\n        self.execute_agent = ExecuteQueryAgent(db_path)\n        self.llm_agent = LLMAgent('phamhai/Llama-3.2-1B-Instruct-Frog')\n        \n    def process_question(self, question: str) -> str:\n        \"\"\"\n        Process user question through the entire pipeline\n        \"\"\"\n        # Step 1: Generate SQL query\n        sql_query = self.sql_agent.generate_query(question)\n        print(f\"Generated SQL query: {sql_query}\")  # For debugging\n        \n        # Step 2: Execute query and get results\n        query_results = self.execute_agent.execute_query(sql_query)\n        print(f\"Query results: {query_results}\")  # For debugging\n        \n        # Step 3: Generate natural language response\n        final_response = self.llm_agent.generate_response(question, query_results)\n        \n        return final_response\n\n# Example usage\nif __name__ == \"__main__\":\n    # Initialize the model\n    db_path = \"/kaggle/input/jidouka-database/db2.db\"\n    chatbot = MultiAgentModel(db_path)\n    \n    # Example questions\n    questions = [\n        \"Có bao nhiêu cải tiến được thực hiện bởi Trần Thị Bình?\",\n        \"Cho tôi biết những cải tiến nào tiết kiệm được nhiều giờ nhất?\",\n        \"Chào bạn\"\n    ]\n    \n    # Process each question\n    for question in questions:\n        print(f\"\\nQuestion: {question}\")\n        response = chatbot.process_question(question)\n        print(f\"Response: {response}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-14T10:08:32.472610Z","iopub.execute_input":"2024-11-14T10:08:32.473082Z","iopub.status.idle":"2024-11-14T10:09:36.619197Z","shell.execute_reply.started":"2024-11-14T10:08:32.473035Z","shell.execute_reply":"2024-11-14T10:09:36.617864Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\nQuestion: Có bao nhiêu cải tiến được thực hiện bởi Trần Thị Bình?\nGenerated SQL query: SELECT COUNT(*) FROM jidouka WHERE tác_giả LIKE LOWER('%Trần Thị Bình%');\nQuery results: [{'COUNT(*)': 0}]\nResponse: Dựa vào dữ liệu được cung cấp, không có thông tin về các cải tiến mà Trần Thị Bình đã thực hiện.\n\nQuestion: Cho tôi biết những cải tiến nào tiết kiệm được nhiều giờ nhất?\nGenerated SQL query: SELECT tên_cải_tiến, số_giờ FROM jidouka GROUP BY số_giờ ORDER BY số_giờ DESC LIMIT 1;\nQuery results: []\nResponse: Tôi không tìm thấy dữ liệu phù hợp với câu hỏi của bạn. Vui lòng thử lại với câu hỏi khác.\n\nQuestion: Chào bạn\nGenerated SQL query: Chào bạn! Tôi không biết về các cải tiến nào có sản phẩm đầu ra là video. Bạn có thể tìm các cải tiến này trên YouTube hoặc các trang web tài liệu công cụ như GitHub hoặc StackOverflow?\nQuery results: []\nResponse: Tôi không tìm thấy dữ liệu phù hợp với câu hỏi của bạn. Vui lòng thử lại với câu hỏi khác.\n","output_type":"stream"}]}]}