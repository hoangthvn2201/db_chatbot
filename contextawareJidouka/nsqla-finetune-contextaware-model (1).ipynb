{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## import packages and model tokenizer","metadata":{}},{"cell_type":"markdown","source":"Important note: change ImprovementContent to ImprovementName , remember to change them after generate answer","metadata":{}},{"cell_type":"code","source":"!pip install torch  --quiet\n\n# # Install Hugging Face libraries\n!pip install  --upgrade transformers datasets accelerate evaluate bitsandbytes --quiet\n\n# #FlashAttention only supports Ampere GPUs or newer. #NEED A100 IN GOOGLE COLAB\n!pip install -U transformers\n# # !pip install -U flash-attn --no-build-isolation --quiet\n\n\n! pip install peft --quiet\n! pip install datasets trl ninja packaging --quiet\n\n# # Uncomment only if you're using A100 GPU\n# #!pip install flash-attn --no-build-isolation\n!pip install diffusers safetensors  --quiet\n\n# %pip install -U wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:12:20.484192Z","iopub.execute_input":"2024-11-22T07:12:20.484775Z","iopub.status.idle":"2024-11-22T07:13:29.417576Z","shell.execute_reply.started":"2024-11-22T07:12:20.484741Z","shell.execute_reply":"2024-11-22T07:13:29.416428Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n    DataCollatorForSeq2Seq,\n    EarlyStoppingCallback\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\nimport os, torch, wandb\nfrom datasets import load_dataset, DatasetDict\nfrom trl import SFTTrainer, setup_chat_format","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:13:29.419431Z","iopub.execute_input":"2024-11-22T07:13:29.419674Z","iopub.status.idle":"2024-11-22T07:13:47.996276Z","shell.execute_reply.started":"2024-11-22T07:13:29.419649Z","shell.execute_reply":"2024-11-22T07:13:47.995586Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\n\nlogin(token = hf_token)\n\nwb_token = user_secrets.get_secret(\"wandb\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='Fine-tune Llama 3 8B on SQL dataset', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:13:47.997257Z","iopub.execute_input":"2024-11-22T07:13:47.997795Z","iopub.status.idle":"2024-11-22T07:13:53.573284Z","shell.execute_reply.started":"2024-11-22T07:13:47.997767Z","shell.execute_reply":"2024-11-22T07:13:53.572483Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhuyhoangt2201\u001b[0m (\u001b[33mhuyhoangt2201-fpt-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111255846666697, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a54075ebcfce476e845dd93a77f992d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241122_071350-2icwjpe9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/huyhoangt2201-fpt-university/Fine-tune%20Llama%203%208B%20on%20SQL%20dataset/runs/2icwjpe9' target=\"_blank\">trim-forest-19</a></strong> to <a href='https://wandb.ai/huyhoangt2201-fpt-university/Fine-tune%20Llama%203%208B%20on%20SQL%20dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/huyhoangt2201-fpt-university/Fine-tune%20Llama%203%208B%20on%20SQL%20dataset' target=\"_blank\">https://wandb.ai/huyhoangt2201-fpt-university/Fine-tune%20Llama%203%208B%20on%20SQL%20dataset</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/huyhoangt2201-fpt-university/Fine-tune%20Llama%203%208B%20on%20SQL%20dataset/runs/2icwjpe9' target=\"_blank\">https://wandb.ai/huyhoangt2201-fpt-university/Fine-tune%20Llama%203%208B%20on%20SQL%20dataset/runs/2icwjpe9</a>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"base_model = \"phamhai/Llama-3.2-1B-Instruct-Frog\"\nnew_model = \"llama-3.2-1b-sql_finetuned_contextaware_1.0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:22:47.639620Z","iopub.execute_input":"2024-11-22T07:22:47.640318Z","iopub.status.idle":"2024-11-22T07:22:47.644603Z","shell.execute_reply.started":"2024-11-22T07:22:47.640285Z","shell.execute_reply":"2024-11-22T07:22:47.643778Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"torch_dtype = torch.float16\n\n# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.float16\n)\n\n# Load model\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    torch_dtype=torch.float32,\n    #attn_implementation=attn_implementation\n)\ntokenizer = AutoTokenizer.from_pretrained(base_model,use_fast=True)\ntokenizer.padding_side = 'right' # to prevent warnings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:13:53.581606Z","iopub.execute_input":"2024-11-22T07:13:53.581955Z","iopub.status.idle":"2024-11-22T07:15:48.294180Z","shell.execute_reply.started":"2024-11-22T07:13:53.581913Z","shell.execute_reply":"2024-11-22T07:15:48.293243Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"659c81d5bb634b8487fef79c6dff4df7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7af4253e190b4894bf708993c7c86d3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10cf665dbb6c4c54b4218f3af0b44c0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89a019fb73994b03815d1337aef869f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d533b70330344aa88ec01315f995c008"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b424e7308a740c5815bc8a1cb60f654"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"peft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n)\nmodel = get_peft_model(model, peft_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:15:48.295426Z","iopub.execute_input":"2024-11-22T07:15:48.296108Z","iopub.status.idle":"2024-11-22T07:15:48.552316Z","shell.execute_reply.started":"2024-11-22T07:15:48.296067Z","shell.execute_reply":"2024-11-22T07:15:48.551393Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from datasets import load_dataset, DatasetDict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:15:48.553372Z","iopub.execute_input":"2024-11-22T07:15:48.553665Z","iopub.status.idle":"2024-11-22T07:15:48.560095Z","shell.execute_reply.started":"2024-11-22T07:15:48.553633Z","shell.execute_reply":"2024-11-22T07:15:48.559246Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"dataset_train = load_dataset(\"huyhoangt2201/contextawareJidouka1.0\", split='train[:95%]')\ndataset_val = load_dataset(\"huyhoangt2201/contextawareJidouka1.0\", split='train[-5%:]')\ndataset = DatasetDict({\n    'train': dataset_train,\n    'validation': dataset_val\n})\ndataset.save_to_disk(\"completed_train_dataset\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:23:51.942360Z","iopub.execute_input":"2024-11-22T07:23:51.943087Z","iopub.status.idle":"2024-11-22T07:23:56.235142Z","shell.execute_reply.started":"2024-11-22T07:23:51.943049Z","shell.execute_reply":"2024-11-22T07:23:56.234321Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/139 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eac3e76a376e4aed9246695edc68e5c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/7 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f43a5a43e54640699e9ea347791036da"}},"metadata":{}}],"execution_count":30},{"cell_type":"markdown","source":"## process data","metadata":{}},{"cell_type":"code","source":"system_prompt = \"\"\"You are an SQL query assistant. Based on schema and context below, generate an SQL query to retrieve the relevant information for the user. If the user’s question is unrelated to the table, respond naturally in user's language.\n\nSchema:\n+Table Author, columns=[AuthorId: int, AuthorName: nvarchar(255)]\n+Table Department, columns=[DepartmentId: int, DepartmentName: nvarchar(255)]\n+Table GroupDC, columns=[GroupDCId: int, DepartmentId: int, GroupDCName nvarchar(255)]\n+Table Job, columns=[JobId: int, JobName: nvarchar(255)]\n+Table Tool, columns=[ToolId: int, ToolName: nvarchar(255), ToolDescription: text]\n+Table Jidouka, columns=[JidoukaId: bigint, ProductApply: nvarchar(255), ImprovementName: nvarchar(255), SoftwareUsing: nvarchar(255), Description: nvarchar(255), Video: text, DetailDocument: text, TotalJobApplied: int, TotalTimeSaved: int, DateCreate: datetime, JobId: int, AuthorId: int, DepartmentId: int, GroupDCId: int]\n+Table JidoukaTool, columns=[JidoukaId: bigint, ToolId: int]\n+Primary_keys=[Author.AuthorId, Department.DepartmentId, GroupDC.GroupDCId, Job.JobId, Tool.ToolId, Jidouka.JidoukaId]\n+Foreign_keys=[GroupDC.DepartmentId=Department.DepartmentId, Jidouka.JobId=Job.JobId, Jidouka.AuthorId=Author.AuthorId, Jidouka.DepartmentId=Department.DepartmentId, Jidouka.GroupDCId=GroupDC.GroupDCId, JidoukaTool.JidoukaId=Jidouka.JidoukaId, JidoukaTool.ToolId=Tool.ToolId]\n\nContext:\nPrevious user question: {previous_question}\nPrevious answer: {previous_answer}\nPrevious schema linking(Format: [Tables, Columns, Foreign keys, Possible cell values]): {schema_linking}\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:23:59.671416Z","iopub.execute_input":"2024-11-22T07:23:59.672006Z","iopub.status.idle":"2024-11-22T07:23:59.677464Z","shell.execute_reply.started":"2024-11-22T07:23:59.671971Z","shell.execute_reply":"2024-11-22T07:23:59.676753Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def format_context(sample):\n    sample['context'] = system_prompt.format(previous_question=sample['previous_question'], previous_answer=sample['previous_answer'], schema_linking=sample['schema_linking'])\n    \n    return sample","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:24:02.563146Z","iopub.execute_input":"2024-11-22T07:24:02.563636Z","iopub.status.idle":"2024-11-22T07:24:02.570102Z","shell.execute_reply.started":"2024-11-22T07:24:02.563585Z","shell.execute_reply":"2024-11-22T07:24:02.569185Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"dataset_train2 = dataset_train.map(format_context)\ndataset_val2 = dataset_val.map(format_context)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:25:02.116825Z","iopub.execute_input":"2024-11-22T07:25:02.117422Z","iopub.status.idle":"2024-11-22T07:25:02.145593Z","shell.execute_reply.started":"2024-11-22T07:25:02.117384Z","shell.execute_reply":"2024-11-22T07:25:02.144826Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec770cc809e046a582163dfc9d92fffc"}},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"dataset_train2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:25:08.387736Z","iopub.execute_input":"2024-11-22T07:25:08.388089Z","iopub.status.idle":"2024-11-22T07:25:08.395174Z","shell.execute_reply.started":"2024-11-22T07:25:08.388057Z","shell.execute_reply":"2024-11-22T07:25:08.394279Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['previous_question', 'previous_answer', 'schema_linking', 'question', 'answer', 'context'],\n    num_rows: 139\n})"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"dataset_train2['train']['context'][2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:18:50.681597Z","iopub.execute_input":"2024-11-22T07:18:50.681936Z","iopub.status.idle":"2024-11-22T07:18:50.689809Z","shell.execute_reply.started":"2024-11-22T07:18:50.681906Z","shell.execute_reply":"2024-11-22T07:18:50.689112Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"\"You are an SQL query assistant. Based on schema and context below, generate an SQL query to retrieve the relevant information for the user. If the user’s question is unrelated to the table, respond naturally in user's language.\\n\\nSchema:\\n+Table Author, columns=[AuthorId: int, AuthorName: nvarchar(255)]\\n+Table Department, columns=[DepartmentId: int, DepartmentName: nvarchar(255)]\\n+Table GroupDC, columns=[GroupDCId: int, DepartmentId: int, GroupDCName nvarchar(255)]\\n+Table Job, columns=[JobId: int, JobName: nvarchar(255)]\\n+Table Tool, columns=[ToolId: int, ToolName: nvarchar(255), ToolDescription: text]\\n+Table Jidouka, columns=[JidoukaId: bigint, ProductApply: nvarchar(255), JobName: nvarchar(255), ImprovementContent: text, SoftwareUsing: nvarchar(255), Description: nvarchar(255), Video: text, DetailDocument: text, TotalJobApplied: int, TotalTimeSaved: int, DateCreate: datetime, JobId: int, AuthorId: int, DepartmentId: int, GroupDCId: int]\\n+Table JidoukaTool, columns=[JidoukaId: bigint, ToolId: int]\\n+Primary_keys=[Author.AuthorId, Department.DepartmentId, GroupDC.GroupDCId, Job.JobId, Tool.ToolId, Jidouka.JidoukaId]\\n+Foreign_keys=[GroupDC.DepartmentId=Department.DepartmentId, Jidouka.JobId=Job.JobId, Jidouka.AuthorId=Author.AuthorId, Jidouka.DepartmentId=Department.DepartmentId, Jidouka.GroupDCId=GroupDC.GroupDCId, JidoukaTool.JidoukaId=Jidouka.JidoukaId, JidoukaTool.ToolId=Tool.ToolId]\\n\\nContext:\\nPrevious user question: What innovations were launched in 2023?\\nPrevious answer: SELECT ImprovementContent, DateCreate FROM Jidouka WHERE YEAR(DateCreate) = 2023;\\nPrevious schema linking(Format: [Tables, Columns, Foreign keys, Possible cell values]): {Tables: [Jidouka], Columns: [Jidouka.ImprovementContent, Jidouka.DateCreate], Foreign keys: [], Possible cell values: [2023]}\\n\""},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"dataset_train3 = dataset_train2.shuffle(seed=42)\ndataset_val3 = dataset_val2.shuffle(seed=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:25:37.772188Z","iopub.execute_input":"2024-11-22T07:25:37.772567Z","iopub.status.idle":"2024-11-22T07:25:37.787486Z","shell.execute_reply.started":"2024-11-22T07:25:37.772533Z","shell.execute_reply":"2024-11-22T07:25:37.786612Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"def format_data_template(sample):\n    chat = [\n          {\"role\":\"system\", \"content\": sample['context']},\n          {\"role\":\"user\", \"content\":sample['question']},\n          {\"role\":\"assistant\",\"content\":sample['answer']}\n    ]\n    return {\n        \"messages\": tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:25:41.026821Z","iopub.execute_input":"2024-11-22T07:25:41.027137Z","iopub.status.idle":"2024-11-22T07:25:41.032887Z","shell.execute_reply.started":"2024-11-22T07:25:41.027111Z","shell.execute_reply":"2024-11-22T07:25:41.032078Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"train_set = dataset_train3.map(format_data_template, remove_columns=['context','question','answer','previous_question', 'previous_answer','schema_linking'])\nval_set = dataset_val3.map(format_data_template, remove_columns=['context','question','answer','previous_question', 'previous_answer','schema_linking'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:26:03.979173Z","iopub.execute_input":"2024-11-22T07:26:03.979826Z","iopub.status.idle":"2024-11-22T07:26:04.370639Z","shell.execute_reply.started":"2024-11-22T07:26:03.979790Z","shell.execute_reply":"2024-11-22T07:26:04.369861Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/139 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1993de0c7818413f886baa10ec1fd923"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec40b289a5f74d9db794acb0bb2d29ea"}},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"train_set['messages'][1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:26:13.868753Z","iopub.execute_input":"2024-11-22T07:26:13.869087Z","iopub.status.idle":"2024-11-22T07:26:13.875985Z","shell.execute_reply.started":"2024-11-22T07:26:13.869058Z","shell.execute_reply":"2024-11-22T07:26:13.875204Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 22 Nov 2024\\n\\nYou are an SQL query assistant. Based on schema and context below, generate an SQL query to retrieve the relevant information for the user. If the user’s question is unrelated to the table, respond naturally in user's language.\\n\\nSchema:\\n+Table Author, columns=[AuthorId: int, AuthorName: nvarchar(255)]\\n+Table Department, columns=[DepartmentId: int, DepartmentName: nvarchar(255)]\\n+Table GroupDC, columns=[GroupDCId: int, DepartmentId: int, GroupDCName nvarchar(255)]\\n+Table Job, columns=[JobId: int, JobName: nvarchar(255)]\\n+Table Tool, columns=[ToolId: int, ToolName: nvarchar(255), ToolDescription: text]\\n+Table Jidouka, columns=[JidoukaId: bigint, ProductApply: nvarchar(255), JobName: nvarchar(255), ImprovementContent: text, SoftwareUsing: nvarchar(255), Description: nvarchar(255), Video: text, DetailDocument: text, TotalJobApplied: int, TotalTimeSaved: int, DateCreate: datetime, JobId: int, AuthorId: int, DepartmentId: int, GroupDCId: int]\\n+Table JidoukaTool, columns=[JidoukaId: bigint, ToolId: int]\\n+Primary_keys=[Author.AuthorId, Department.DepartmentId, GroupDC.GroupDCId, Job.JobId, Tool.ToolId, Jidouka.JidoukaId]\\n+Foreign_keys=[GroupDC.DepartmentId=Department.DepartmentId, Jidouka.JobId=Job.JobId, Jidouka.AuthorId=Author.AuthorId, Jidouka.DepartmentId=Department.DepartmentId, Jidouka.GroupDCId=GroupDC.GroupDCId, JidoukaTool.JidoukaId=Jidouka.JidoukaId, JidoukaTool.ToolId=Tool.ToolId]\\n\\nContext:\\nPrevious user question: Who is the author of innovation with ID 2525?\\nPrevious answer: SELECT AuthorName FROM Author JOIN Jidouka ON Author.AuthorId = Jidouka.AuthorId WHERE Jidouka.JidoukaId = 2525;\\nPrevious schema linking(Format: [Tables, Columns, Foreign keys, Possible cell values]): {Tables: [Author, Jidouka], Columns: [Author.AuthorName, Jidouka.JidoukaId], Foreign keys: [Jidouka.AuthorId=Author.AuthorId], Possible cell values: [2525]}<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWhat tools were used in this innovation?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nSELECT Tool.ToolName FROM Tool JOIN JidoukaTool ON Tool.ToolId = JidoukaTool.ToolId WHERE JidoukaTool.JidoukaId = 2525;<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\""},"metadata":{}}],"execution_count":39},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"early_stopping_callback = EarlyStoppingCallback( \n    early_stopping_patience=5\n)\n\ntraining_arguments = TrainingArguments(\n    output_dir=new_model,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    gradient_accumulation_steps=4,\n    optim=\"adamw_8bit\",\n    num_train_epochs=30,\n    eval_strategy=\"epoch\",\n    eval_steps=0.2,\n    save_strategy='epoch',\n    logging_steps=1,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=False,\n    bf16=True,\n    group_by_length=True,\n    report_to=\"wandb\",\n    load_best_model_at_end = True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:22:53.873279Z","iopub.execute_input":"2024-11-22T07:22:53.873923Z","iopub.status.idle":"2024-11-22T07:22:53.910592Z","shell.execute_reply.started":"2024-11-22T07:22:53.873890Z","shell.execute_reply":"2024-11-22T07:22:53.909654Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = train_set,\n    eval_dataset = val_set,\n    dataset_text_field = 'messages',\n    max_seq_length = 2048, \n    peft_config = peft_config, \n    packing=False,\n    args = training_arguments,\n    callbacks=[early_stopping_callback]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:26:52.831338Z","iopub.execute_input":"2024-11-22T07:26:52.831712Z","iopub.status.idle":"2024-11-22T07:26:53.588185Z","shell.execute_reply.started":"2024-11-22T07:26:52.831665Z","shell.execute_reply":"2024-11-22T07:26:53.587118Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/139 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fce7ae0252bc43d4ba1d7f8ace4ac8da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67a0d361dfad4c49887a41f6220d48c7"}},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"%%time\n\neot = \"<|eot_id|>\"\neot_id = tokenizer.convert_tokens_to_ids(eot)\ntokenizer.pad_token = eot\ntokenizer.pad_token_id = eot_id\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:27:00.526091Z","iopub.execute_input":"2024-11-22T07:27:00.526662Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='110' max='510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [110/510 27:41 < 1:42:34, 0.06 it/s, Epoch 6.23/30]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.199300</td>\n      <td>0.197413</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.087200</td>\n      <td>0.096994</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.049600</td>\n      <td>0.055776</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.040700</td>\n      <td>0.053381</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"adapter_model = new_model+'_adapter'\nadapter_model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.model.save_pretrained(adapter_model)\ntrainer.model.push_to_hub(adapter_model, use_temp_dir=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"adapter_model = 'huyhoangt2201/' + adapter_model\nbase_model = 'phamhai/Llama-3.2-1B-Instruct-Frog'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(base_model)\n\nbase_model_reload = AutoModelForCausalLM.from_pretrained(\n        base_model,\n        return_dict=True,\n        low_cpu_mem_usage=True,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n)\n\n# base_model_reload, tokenizer = setup_chat_format(base_model_reload, tokenizer)\n\n# Merge adapter with base model\nmerge_model = PeftModel.from_pretrained(base_model_reload, adapter_model)\n\nmerge_model = merge_model.merge_and_unload()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_model = new_model + '_merged'\nmerge_model.save_pretrained(merged_model)\ntokenizer.save_pretrained(merged_model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\nlogin(token = hf_token)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merge_model.push_to_hub(merged_model, use_temp_dir=False)\ntokenizer.push_to_hub(merged_model, use_temp_dir=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}