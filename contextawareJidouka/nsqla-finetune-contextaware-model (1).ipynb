{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## import packages and model tokenizer","metadata":{}},{"cell_type":"markdown","source":"Important note: change ImprovementContent to ImprovementName , remember to change them after generate answer","metadata":{}},{"cell_type":"code","source":"!pip install torch  --quiet\n\n# # Install Hugging Face libraries\n!pip install  --upgrade transformers datasets accelerate evaluate bitsandbytes --quiet\n\n# #FlashAttention only supports Ampere GPUs or newer. #NEED A100 IN GOOGLE COLAB\n!pip install -U transformers\n# # !pip install -U flash-attn --no-build-isolation --quiet\n\n\n! pip install peft --quiet\n! pip install datasets trl ninja packaging --quiet\n\n# # Uncomment only if you're using A100 GPU\n# #!pip install flash-attn --no-build-isolation\n!pip install diffusers safetensors  --quiet\n\n# %pip install -U wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:12:20.484192Z","iopub.execute_input":"2024-11-22T07:12:20.484775Z","iopub.status.idle":"2024-11-22T07:13:29.417576Z","shell.execute_reply.started":"2024-11-22T07:12:20.484741Z","shell.execute_reply":"2024-11-22T07:13:29.416428Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n    DataCollatorForSeq2Seq,\n    EarlyStoppingCallback\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\nimport os, torch, wandb\nfrom datasets import load_dataset, DatasetDict\nfrom trl import SFTTrainer, setup_chat_format","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:13:29.419431Z","iopub.execute_input":"2024-11-22T07:13:29.419674Z","iopub.status.idle":"2024-11-22T07:13:47.996276Z","shell.execute_reply.started":"2024-11-22T07:13:29.419649Z","shell.execute_reply":"2024-11-22T07:13:47.995586Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\n\nlogin(token = hf_token)\n\nwb_token = user_secrets.get_secret(\"wandb\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='Fine-tune Llama 3 8B on SQL dataset', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:13:47.997257Z","iopub.execute_input":"2024-11-22T07:13:47.997795Z","iopub.status.idle":"2024-11-22T07:13:53.573284Z","shell.execute_reply.started":"2024-11-22T07:13:47.997767Z","shell.execute_reply":"2024-11-22T07:13:53.572483Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhuyhoangt2201\u001b[0m (\u001b[33mhuyhoangt2201-fpt-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111255846666697, max=1.0)â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a54075ebcfce476e845dd93a77f992d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241122_071350-2icwjpe9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/huyhoangt2201-fpt-university/Fine-tune%20Llama%203%208B%20on%20SQL%20dataset/runs/2icwjpe9' target=\"_blank\">trim-forest-19</a></strong> to <a href='https://wandb.ai/huyhoangt2201-fpt-university/Fine-tune%20Llama%203%208B%20on%20SQL%20dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/huyhoangt2201-fpt-university/Fine-tune%20Llama%203%208B%20on%20SQL%20dataset' target=\"_blank\">https://wandb.ai/huyhoangt2201-fpt-university/Fine-tune%20Llama%203%208B%20on%20SQL%20dataset</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/huyhoangt2201-fpt-university/Fine-tune%20Llama%203%208B%20on%20SQL%20dataset/runs/2icwjpe9' target=\"_blank\">https://wandb.ai/huyhoangt2201-fpt-university/Fine-tune%20Llama%203%208B%20on%20SQL%20dataset/runs/2icwjpe9</a>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"base_model = \"phamhai/Llama-3.2-1B-Instruct-Frog\"\nnew_model = \"llama-3.2-1b-sql_finetuned_contextaware_1.0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:22:47.639620Z","iopub.execute_input":"2024-11-22T07:22:47.640318Z","iopub.status.idle":"2024-11-22T07:22:47.644603Z","shell.execute_reply.started":"2024-11-22T07:22:47.640285Z","shell.execute_reply":"2024-11-22T07:22:47.643778Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"torch_dtype = torch.float16\n\n# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.float16\n)\n\n# Load model\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    torch_dtype=torch.float32,\n    #attn_implementation=attn_implementation\n)\ntokenizer = AutoTokenizer.from_pretrained(base_model,use_fast=True)\ntokenizer.padding_side = 'right' # to prevent warnings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:13:53.581606Z","iopub.execute_input":"2024-11-22T07:13:53.581955Z","iopub.status.idle":"2024-11-22T07:15:48.294180Z","shell.execute_reply.started":"2024-11-22T07:13:53.581913Z","shell.execute_reply":"2024-11-22T07:15:48.293243Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"659c81d5bb634b8487fef79c6dff4df7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7af4253e190b4894bf708993c7c86d3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10cf665dbb6c4c54b4218f3af0b44c0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89a019fb73994b03815d1337aef869f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d533b70330344aa88ec01315f995c008"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b424e7308a740c5815bc8a1cb60f654"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"peft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n)\nmodel = get_peft_model(model, peft_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:15:48.295426Z","iopub.execute_input":"2024-11-22T07:15:48.296108Z","iopub.status.idle":"2024-11-22T07:15:48.552316Z","shell.execute_reply.started":"2024-11-22T07:15:48.296067Z","shell.execute_reply":"2024-11-22T07:15:48.551393Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from datasets import load_dataset, DatasetDict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:15:48.553372Z","iopub.execute_input":"2024-11-22T07:15:48.553665Z","iopub.status.idle":"2024-11-22T07:15:48.560095Z","shell.execute_reply.started":"2024-11-22T07:15:48.553633Z","shell.execute_reply":"2024-11-22T07:15:48.559246Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"dataset_train = load_dataset(\"huyhoangt2201/contextawareJidouka1.0\", split='train[:95%]')\ndataset_val = load_dataset(\"huyhoangt2201/contextawareJidouka1.0\", split='train[-5%:]')\ndataset = DatasetDict({\n    'train': dataset_train,\n    'validation': dataset_val\n})\ndataset.save_to_disk(\"completed_train_dataset\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:23:51.942360Z","iopub.execute_input":"2024-11-22T07:23:51.943087Z","iopub.status.idle":"2024-11-22T07:23:56.235142Z","shell.execute_reply.started":"2024-11-22T07:23:51.943049Z","shell.execute_reply":"2024-11-22T07:23:56.234321Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/139 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eac3e76a376e4aed9246695edc68e5c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/7 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f43a5a43e54640699e9ea347791036da"}},"metadata":{}}],"execution_count":30},{"cell_type":"markdown","source":"## process data","metadata":{}},{"cell_type":"code","source":"system_prompt = \"\"\"You are an SQL query assistant. Based on schema and context below, generate an SQL query to retrieve the relevant information for the user. If the userâ€™s question is unrelated to the table, respond naturally in user's language.\n\nSchema:\n+Table Author, columns=[AuthorId: int, AuthorName: nvarchar(255)]\n+Table Department, columns=[DepartmentId: int, DepartmentName: nvarchar(255)]\n+Table GroupDC, columns=[GroupDCId: int, DepartmentId: int, GroupDCName nvarchar(255)]\n+Table Job, columns=[JobId: int, JobName: nvarchar(255)]\n+Table Tool, columns=[ToolId: int, ToolName: nvarchar(255), ToolDescription: text]\n+Table Jidouka, columns=[JidoukaId: bigint, ProductApply: nvarchar(255), ImprovementName: nvarchar(255), SoftwareUsing: nvarchar(255), Description: nvarchar(255), Video: text, DetailDocument: text, TotalJobApplied: int, TotalTimeSaved: int, DateCreate: datetime, JobId: int, AuthorId: int, DepartmentId: int, GroupDCId: int]\n+Table JidoukaTool, columns=[JidoukaId: bigint, ToolId: int]\n+Primary_keys=[Author.AuthorId, Department.DepartmentId, GroupDC.GroupDCId, Job.JobId, Tool.ToolId, Jidouka.JidoukaId]\n+Foreign_keys=[GroupDC.DepartmentId=Department.DepartmentId, Jidouka.JobId=Job.JobId, Jidouka.AuthorId=Author.AuthorId, Jidouka.DepartmentId=Department.DepartmentId, Jidouka.GroupDCId=GroupDC.GroupDCId, JidoukaTool.JidoukaId=Jidouka.JidoukaId, JidoukaTool.ToolId=Tool.ToolId]\n\nContext:\nPrevious user question: {previous_question}\nPrevious answer: {previous_answer}\nPrevious schema linking(Format: [Tables, Columns, Foreign keys, Possible cell values]): {schema_linking}\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:23:59.671416Z","iopub.execute_input":"2024-11-22T07:23:59.672006Z","iopub.status.idle":"2024-11-22T07:23:59.677464Z","shell.execute_reply.started":"2024-11-22T07:23:59.671971Z","shell.execute_reply":"2024-11-22T07:23:59.676753Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def format_context(sample):\n    sample['context'] = system_prompt.format(previous_question=sample['previous_question'], previous_answer=sample['previous_answer'], schema_linking=sample['schema_linking'])\n    \n    return sample","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:24:02.563146Z","iopub.execute_input":"2024-11-22T07:24:02.563636Z","iopub.status.idle":"2024-11-22T07:24:02.570102Z","shell.execute_reply.started":"2024-11-22T07:24:02.563585Z","shell.execute_reply":"2024-11-22T07:24:02.569185Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"dataset_train2 = dataset_train.map(format_context)\ndataset_val2 = dataset_val.map(format_context)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:25:02.116825Z","iopub.execute_input":"2024-11-22T07:25:02.117422Z","iopub.status.idle":"2024-11-22T07:25:02.145593Z","shell.execute_reply.started":"2024-11-22T07:25:02.117384Z","shell.execute_reply":"2024-11-22T07:25:02.144826Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec770cc809e046a582163dfc9d92fffc"}},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"dataset_train2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:25:08.387736Z","iopub.execute_input":"2024-11-22T07:25:08.388089Z","iopub.status.idle":"2024-11-22T07:25:08.395174Z","shell.execute_reply.started":"2024-11-22T07:25:08.388057Z","shell.execute_reply":"2024-11-22T07:25:08.394279Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['previous_question', 'previous_answer', 'schema_linking', 'question', 'answer', 'context'],\n    num_rows: 139\n})"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"dataset_train2['train']['context'][2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:18:50.681597Z","iopub.execute_input":"2024-11-22T07:18:50.681936Z","iopub.status.idle":"2024-11-22T07:18:50.689809Z","shell.execute_reply.started":"2024-11-22T07:18:50.681906Z","shell.execute_reply":"2024-11-22T07:18:50.689112Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"\"You are an SQL query assistant. Based on schema and context below, generate an SQL query to retrieve the relevant information for the user. If the userâ€™s question is unrelated to the table, respond naturally in user's language.\\n\\nSchema:\\n+Table Author, columns=[AuthorId: int, AuthorName: nvarchar(255)]\\n+Table Department, columns=[DepartmentId: int, DepartmentName: nvarchar(255)]\\n+Table GroupDC, columns=[GroupDCId: int, DepartmentId: int, GroupDCName nvarchar(255)]\\n+Table Job, columns=[JobId: int, JobName: nvarchar(255)]\\n+Table Tool, columns=[ToolId: int, ToolName: nvarchar(255), ToolDescription: text]\\n+Table Jidouka, columns=[JidoukaId: bigint, ProductApply: nvarchar(255), JobName: nvarchar(255), ImprovementContent: text, SoftwareUsing: nvarchar(255), Description: nvarchar(255), Video: text, DetailDocument: text, TotalJobApplied: int, TotalTimeSaved: int, DateCreate: datetime, JobId: int, AuthorId: int, DepartmentId: int, GroupDCId: int]\\n+Table JidoukaTool, columns=[JidoukaId: bigint, ToolId: int]\\n+Primary_keys=[Author.AuthorId, Department.DepartmentId, GroupDC.GroupDCId, Job.JobId, Tool.ToolId, Jidouka.JidoukaId]\\n+Foreign_keys=[GroupDC.DepartmentId=Department.DepartmentId, Jidouka.JobId=Job.JobId, Jidouka.AuthorId=Author.AuthorId, Jidouka.DepartmentId=Department.DepartmentId, Jidouka.GroupDCId=GroupDC.GroupDCId, JidoukaTool.JidoukaId=Jidouka.JidoukaId, JidoukaTool.ToolId=Tool.ToolId]\\n\\nContext:\\nPrevious user question: What innovations were launched in 2023?\\nPrevious answer: SELECT ImprovementContent, DateCreate FROM Jidouka WHERE YEAR(DateCreate) = 2023;\\nPrevious schema linking(Format: [Tables, Columns, Foreign keys, Possible cell values]): {Tables: [Jidouka], Columns: [Jidouka.ImprovementContent, Jidouka.DateCreate], Foreign keys: [], Possible cell values: [2023]}\\n\""},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"dataset_train3 = dataset_train2.shuffle(seed=42)\ndataset_val3 = dataset_val2.shuffle(seed=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:25:37.772188Z","iopub.execute_input":"2024-11-22T07:25:37.772567Z","iopub.status.idle":"2024-11-22T07:25:37.787486Z","shell.execute_reply.started":"2024-11-22T07:25:37.772533Z","shell.execute_reply":"2024-11-22T07:25:37.786612Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"def format_data_template(sample):\n    chat = [\n          {\"role\":\"system\", \"content\": sample['context']},\n          {\"role\":\"user\", \"content\":sample['question']},\n          {\"role\":\"assistant\",\"content\":sample['answer']}\n    ]\n    return {\n        \"messages\": tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:25:41.026821Z","iopub.execute_input":"2024-11-22T07:25:41.027137Z","iopub.status.idle":"2024-11-22T07:25:41.032887Z","shell.execute_reply.started":"2024-11-22T07:25:41.027111Z","shell.execute_reply":"2024-11-22T07:25:41.032078Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"train_set = dataset_train3.map(format_data_template, remove_columns=['context','question','answer','previous_question', 'previous_answer','schema_linking'])\nval_set = dataset_val3.map(format_data_template, remove_columns=['context','question','answer','previous_question', 'previous_answer','schema_linking'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:26:03.979173Z","iopub.execute_input":"2024-11-22T07:26:03.979826Z","iopub.status.idle":"2024-11-22T07:26:04.370639Z","shell.execute_reply.started":"2024-11-22T07:26:03.979790Z","shell.execute_reply":"2024-11-22T07:26:04.369861Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/139 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1993de0c7818413f886baa10ec1fd923"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec40b289a5f74d9db794acb0bb2d29ea"}},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"train_set['messages'][1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:26:13.868753Z","iopub.execute_input":"2024-11-22T07:26:13.869087Z","iopub.status.idle":"2024-11-22T07:26:13.875985Z","shell.execute_reply.started":"2024-11-22T07:26:13.869058Z","shell.execute_reply":"2024-11-22T07:26:13.875204Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 22 Nov 2024\\n\\nYou are an SQL query assistant. Based on schema and context below, generate an SQL query to retrieve the relevant information for the user. If the userâ€™s question is unrelated to the table, respond naturally in user's language.\\n\\nSchema:\\n+Table Author, columns=[AuthorId: int, AuthorName: nvarchar(255)]\\n+Table Department, columns=[DepartmentId: int, DepartmentName: nvarchar(255)]\\n+Table GroupDC, columns=[GroupDCId: int, DepartmentId: int, GroupDCName nvarchar(255)]\\n+Table Job, columns=[JobId: int, JobName: nvarchar(255)]\\n+Table Tool, columns=[ToolId: int, ToolName: nvarchar(255), ToolDescription: text]\\n+Table Jidouka, columns=[JidoukaId: bigint, ProductApply: nvarchar(255), JobName: nvarchar(255), ImprovementContent: text, SoftwareUsing: nvarchar(255), Description: nvarchar(255), Video: text, DetailDocument: text, TotalJobApplied: int, TotalTimeSaved: int, DateCreate: datetime, JobId: int, AuthorId: int, DepartmentId: int, GroupDCId: int]\\n+Table JidoukaTool, columns=[JidoukaId: bigint, ToolId: int]\\n+Primary_keys=[Author.AuthorId, Department.DepartmentId, GroupDC.GroupDCId, Job.JobId, Tool.ToolId, Jidouka.JidoukaId]\\n+Foreign_keys=[GroupDC.DepartmentId=Department.DepartmentId, Jidouka.JobId=Job.JobId, Jidouka.AuthorId=Author.AuthorId, Jidouka.DepartmentId=Department.DepartmentId, Jidouka.GroupDCId=GroupDC.GroupDCId, JidoukaTool.JidoukaId=Jidouka.JidoukaId, JidoukaTool.ToolId=Tool.ToolId]\\n\\nContext:\\nPrevious user question: Who is the author of innovation with ID 2525?\\nPrevious answer: SELECT AuthorName FROM Author JOIN Jidouka ON Author.AuthorId = Jidouka.AuthorId WHERE Jidouka.JidoukaId = 2525;\\nPrevious schema linking(Format: [Tables, Columns, Foreign keys, Possible cell values]): {Tables: [Author, Jidouka], Columns: [Author.AuthorName, Jidouka.JidoukaId], Foreign keys: [Jidouka.AuthorId=Author.AuthorId], Possible cell values: [2525]}<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWhat tools were used in this innovation?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nSELECT Tool.ToolName FROM Tool JOIN JidoukaTool ON Tool.ToolId = JidoukaTool.ToolId WHERE JidoukaTool.JidoukaId = 2525;<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\""},"metadata":{}}],"execution_count":39},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"early_stopping_callback = EarlyStoppingCallback( \n    early_stopping_patience=5\n)\n\ntraining_arguments = TrainingArguments(\n    output_dir=new_model,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    gradient_accumulation_steps=4,\n    optim=\"adamw_8bit\",\n    num_train_epochs=30,\n    eval_strategy=\"epoch\",\n    eval_steps=0.2,\n    save_strategy='epoch',\n    logging_steps=1,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=False,\n    bf16=True,\n    group_by_length=True,\n    report_to=\"wandb\",\n    load_best_model_at_end = True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:22:53.873279Z","iopub.execute_input":"2024-11-22T07:22:53.873923Z","iopub.status.idle":"2024-11-22T07:22:53.910592Z","shell.execute_reply.started":"2024-11-22T07:22:53.873890Z","shell.execute_reply":"2024-11-22T07:22:53.909654Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = train_set,\n    eval_dataset = val_set,\n    dataset_text_field = 'messages',\n    max_seq_length = 2048, \n    peft_config = peft_config, \n    packing=False,\n    args = training_arguments,\n    callbacks=[early_stopping_callback]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:26:52.831338Z","iopub.execute_input":"2024-11-22T07:26:52.831712Z","iopub.status.idle":"2024-11-22T07:26:53.588185Z","shell.execute_reply.started":"2024-11-22T07:26:52.831665Z","shell.execute_reply":"2024-11-22T07:26:53.587118Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/139 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fce7ae0252bc43d4ba1d7f8ace4ac8da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67a0d361dfad4c49887a41f6220d48c7"}},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"%%time\n\neot = \"<|eot_id|>\"\neot_id = tokenizer.convert_tokens_to_ids(eot)\ntokenizer.pad_token = eot\ntokenizer.pad_token_id = eot_id\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:27:00.526091Z","iopub.execute_input":"2024-11-22T07:27:00.526662Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='110' max='510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [110/510 27:41 < 1:42:34, 0.06 it/s, Epoch 6.23/30]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.199300</td>\n      <td>0.197413</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.087200</td>\n      <td>0.096994</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.049600</td>\n      <td>0.055776</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.040700</td>\n      <td>0.053381</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"adapter_model = new_model+'_adapter'\nadapter_model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.model.save_pretrained(adapter_model)\ntrainer.model.push_to_hub(adapter_model, use_temp_dir=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"adapter_model = 'huyhoangt2201/' + adapter_model\nbase_model = 'phamhai/Llama-3.2-1B-Instruct-Frog'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(base_model)\n\nbase_model_reload = AutoModelForCausalLM.from_pretrained(\n        base_model,\n        return_dict=True,\n        low_cpu_mem_usage=True,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n)\n\n# base_model_reload, tokenizer = setup_chat_format(base_model_reload, tokenizer)\n\n# Merge adapter with base model\nmerge_model = PeftModel.from_pretrained(base_model_reload, adapter_model)\n\nmerge_model = merge_model.merge_and_unload()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_model = new_model + '_merged'\nmerge_model.save_pretrained(merged_model)\ntokenizer.save_pretrained(merged_model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\nlogin(token = hf_token)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merge_model.push_to_hub(merged_model, use_temp_dir=False)\ntokenizer.push_to_hub(merged_model, use_temp_dir=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}