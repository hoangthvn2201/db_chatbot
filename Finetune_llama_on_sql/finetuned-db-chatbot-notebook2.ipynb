{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9818870,"sourceType":"datasetVersion","datasetId":5983756},{"sourceId":205691277,"sourceType":"kernelVersion"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch tensorboard --quiet\n\n# Install Hugging Face libraries\n!pip install  --upgrade transformers datasets accelerate evaluate bitsandbytes --quiet\n\n#FlashAttention only supports Ampere GPUs or newer. #NEED A100 IN GOOGLE COLAB\n#!pip install -U transformers\n!pip install -U flash-attn --no-build-isolation --quiet\n\n\n! pip install peft --quiet\n! pip install datasets trl ninja packaging --quiet\n\n# Uncomment only if you're using A100 GPU\n#!pip install flash-attn --no-build-isolation\n!pip install diffusers safetensors  --quiet\n\n%pip install -U wandb","metadata":{"execution":{"iopub.status.busy":"2024-11-07T01:10:49.100820Z","iopub.execute_input":"2024-11-07T01:10:49.101115Z","iopub.status.idle":"2024-11-07T01:13:35.894518Z","shell.execute_reply.started":"2024-11-07T01:10:49.101082Z","shell.execute_reply":"2024-11-07T01:13:35.893383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\nimport os, torch, wandb\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, setup_chat_format","metadata":{"execution":{"iopub.status.busy":"2024-11-07T01:13:35.896586Z","iopub.execute_input":"2024-11-07T01:13:35.896916Z","iopub.status.idle":"2024-11-07T01:13:59.466289Z","shell.execute_reply.started":"2024-11-07T01:13:35.896881Z","shell.execute_reply":"2024-11-07T01:13:59.465538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\n\nlogin(token = hf_token)\n\nwb_token = user_secrets.get_secret(\"wandb\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='Fine-tune Llama 3 8B on SQL dataset', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T01:13:59.467504Z","iopub.execute_input":"2024-11-07T01:13:59.468235Z","iopub.status.idle":"2024-11-07T01:14:04.079609Z","shell.execute_reply.started":"2024-11-07T01:13:59.468199Z","shell.execute_reply":"2024-11-07T01:14:04.078745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = \"phamhai/Llama-3.2-3B-Instruct-Frog\"\ndataset_path = \"/kaggle/input/sql-dataset/train_dataset.json\"\nnew_model = \"llama-3.2-3b-chat-sql\"","metadata":{"execution":{"iopub.status.busy":"2024-11-07T01:14:19.178289Z","iopub.execute_input":"2024-11-07T01:14:19.179156Z","iopub.status.idle":"2024-11-07T01:14:19.184122Z","shell.execute_reply.started":"2024-11-07T01:14:19.179113Z","shell.execute_reply":"2024-11-07T01:14:19.183162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch_dtype = torch.float16","metadata":{"execution":{"iopub.status.busy":"2024-11-07T01:14:26.563256Z","iopub.execute_input":"2024-11-07T01:14:26.563639Z","iopub.status.idle":"2024-11-07T01:14:26.568836Z","shell.execute_reply.started":"2024-11-07T01:14:26.563605Z","shell.execute_reply":"2024-11-07T01:14:26.567975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.float16\n)\n\n# Load model\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    torch_dtype=torch.float16\n    #attn_implementation=attn_implementation\n)\ntokenizer = AutoTokenizer.from_pretrained(base_model,use_fast=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T01:14:30.211300Z","iopub.execute_input":"2024-11-07T01:14:30.211696Z","iopub.status.idle":"2024-11-07T01:17:17.424249Z","shell.execute_reply.started":"2024-11-07T01:14:30.211660Z","shell.execute_reply":"2024-11-07T01:17:17.423261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LoRA config\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n)\nmodel = get_peft_model(model, peft_config)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T01:17:21.628151Z","iopub.execute_input":"2024-11-07T01:17:21.629018Z","iopub.status.idle":"2024-11-07T01:17:22.189495Z","shell.execute_reply.started":"2024-11-07T01:17:21.628976Z","shell.execute_reply":"2024-11-07T01:17:22.188501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = load_dataset(\"json\", data_files=dataset_path,split=\"train\")","metadata":{"execution":{"iopub.status.busy":"2024-11-07T01:17:25.635876Z","iopub.execute_input":"2024-11-07T01:17:25.636582Z","iopub.status.idle":"2024-11-07T01:17:26.628696Z","shell.execute_reply.started":"2024-11-07T01:17:25.636537Z","shell.execute_reply":"2024-11-07T01:17:26.627860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = train_set.train_test_split(test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T01:17:38.861237Z","iopub.execute_input":"2024-11-07T01:17:38.861736Z","iopub.status.idle":"2024-11-07T01:17:38.886740Z","shell.execute_reply.started":"2024-11-07T01:17:38.861686Z","shell.execute_reply":"2024-11-07T01:17:38.885756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=new_model,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n    num_train_epochs=1,\n    eval_strategy=\"steps\",\n    eval_steps=0.2,\n    logging_steps=1,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=False,\n    bf16=False,\n    group_by_length=True,\n    report_to=\"wandb\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T01:18:00.504592Z","iopub.execute_input":"2024-11-07T01:18:00.504975Z","iopub.status.idle":"2024-11-07T01:18:00.533638Z","shell.execute_reply.started":"2024-11-07T01:18:00.504938Z","shell.execute_reply":"2024-11-07T01:18:00.532777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=train_set[\"train\"],\n    eval_dataset=train_set[\"test\"],\n    peft_config=peft_config,\n    max_seq_length=512,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing= False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T01:18:03.507917Z","iopub.execute_input":"2024-11-07T01:18:03.508832Z","iopub.status.idle":"2024-11-07T01:18:10.190640Z","shell.execute_reply.started":"2024-11-07T01:18:03.508787Z","shell.execute_reply":"2024-11-07T01:18:10.189728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eot = \"<|eot_id|>\"\neot_id = tokenizer.convert_tokens_to_ids(eot)\ntokenizer.pad_token = eot\ntokenizer.pad_token_id = eot_id","metadata":{"execution":{"iopub.status.busy":"2024-11-07T01:18:32.869847Z","iopub.execute_input":"2024-11-07T01:18:32.870242Z","iopub.status.idle":"2024-11-07T01:18:32.875713Z","shell.execute_reply.started":"2024-11-07T01:18:32.870203Z","shell.execute_reply":"2024-11-07T01:18:32.874777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-11-07T01:18:35.540039Z","iopub.execute_input":"2024-11-07T01:18:35.540437Z","iopub.status.idle":"2024-11-07T03:42:41.999033Z","shell.execute_reply.started":"2024-11-07T01:18:35.540399Z","shell.execute_reply":"2024-11-07T03:42:41.998142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()\nmodel.config.use_cache = True","metadata":{"execution":{"iopub.status.busy":"2024-11-07T03:42:42.000472Z","iopub.execute_input":"2024-11-07T03:42:42.000781Z","iopub.status.idle":"2024-11-07T03:42:44.934306Z","shell.execute_reply.started":"2024-11-07T03:42:42.000748Z","shell.execute_reply":"2024-11-07T03:42:44.933466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.model.save_pretrained(new_model)\ntrainer.model.push_to_hub(new_model, use_temp_dir=False)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T03:42:44.935371Z","iopub.execute_input":"2024-11-07T03:42:44.935646Z","iopub.status.idle":"2024-11-07T03:42:57.419549Z","shell.execute_reply.started":"2024-11-07T03:42:44.935615Z","shell.execute_reply":"2024-11-07T03:42:57.418586Z"},"trusted":true},"execution_count":null,"outputs":[]}]}