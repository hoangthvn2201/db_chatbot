{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9834962,"sourceType":"datasetVersion","datasetId":6032626}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U bitsandbytes transformers peft accelerate datasets scipy einops ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T03:51:20.298811Z","iopub.execute_input":"2024-11-08T03:51:20.299313Z","iopub.status.idle":"2024-11-08T03:51:54.747143Z","shell.execute_reply.started":"2024-11-08T03:51:20.299240Z","shell.execute_reply":"2024-11-08T03:51:54.745995Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport time\nimport numpy as np\nimport pandas as pd\nfrom typing import Dict, List\n\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom datasets import load_dataset, DatasetDict\nfrom transformers import (\n    AutoModelForSeq2SeqLM,\n    AutoModelForCausalLM,\n    AutoTokenizer, \n    TrainingArguments, \n    Trainer,\n    EarlyStoppingCallback\n)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-08T03:51:57.669861Z","iopub.execute_input":"2024-11-08T03:51:57.670752Z","iopub.status.idle":"2024-11-08T03:52:21.541733Z","shell.execute_reply.started":"2024-11-08T03:51:57.670705Z","shell.execute_reply":"2024-11-08T03:52:21.540631Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"os.environ['WANDB_DISABLED']=\"true\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T03:52:25.821753Z","iopub.execute_input":"2024-11-08T03:52:25.822481Z","iopub.status.idle":"2024-11-08T03:52:25.827089Z","shell.execute_reply.started":"2024-11-08T03:52:25.822440Z","shell.execute_reply":"2024-11-08T03:52:25.826169Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T03:52:27.470474Z","iopub.execute_input":"2024-11-08T03:52:27.470839Z","iopub.status.idle":"2024-11-08T03:52:27.541493Z","shell.execute_reply.started":"2024-11-08T03:52:27.470802Z","shell.execute_reply":"2024-11-08T03:52:27.540198Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T03:52:28.484573Z","iopub.execute_input":"2024-11-08T03:52:28.485040Z","iopub.status.idle":"2024-11-08T03:52:28.491345Z","shell.execute_reply.started":"2024-11-08T03:52:28.484997Z","shell.execute_reply":"2024-11-08T03:52:28.489958Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### Load model","metadata":{}},{"cell_type":"code","source":"model_name = 'Biscottezi/vit5-base-finetuned-vitext2sql'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\noriginal_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\noriginal_model = original_model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T03:52:30.481429Z","iopub.execute_input":"2024-11-08T03:52:30.481893Z","iopub.status.idle":"2024-11-08T03:52:55.830736Z","shell.execute_reply.started":"2024-11-08T03:52:30.481848Z","shell.execute_reply":"2024-11-08T03:52:55.829934Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.45k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"995a19d24d494aaeb000e6758ec3eaaa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/820k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0ba15faf0254e0bbfb05b20420da29d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8438cf8791a44fd681ab8c1f89798fa6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7393fe2aa6e745f99b24c8485f5d7472"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/741 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d675a528a369419da23e80fb695478c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/904M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0049e452dce049728329cdfa19196e99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98626af1eb6548e2a2cfd67715225edb"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"original_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T03:52:57.693099Z","iopub.execute_input":"2024-11-08T03:52:57.694402Z","iopub.status.idle":"2024-11-08T03:52:57.711722Z","shell.execute_reply.started":"2024-11-08T03:52:57.694336Z","shell.execute_reply":"2024-11-08T03:52:57.710482Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(36096, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(36096, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(36096, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n)"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"### Load dataset","metadata":{}},{"cell_type":"code","source":"dataset_train = load_dataset(\"hieulhwork24/custom-vietnamese-text2sql\", split='train[:90%]')\ndataset_val = load_dataset(\"hieulhwork24/custom-vietnamese-text2sql\", split='train[-10%:]')\ndataset = DatasetDict({\n    'train': dataset_train,\n    'validation': dataset_val\n})\ndataset.save_to_disk(\"completed_train_dataset\")\nprint(\"Created train dataset!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T03:53:04.785689Z","iopub.execute_input":"2024-11-08T03:53:04.786743Z","iopub.status.idle":"2024-11-08T03:53:06.493588Z","shell.execute_reply.started":"2024-11-08T03:53:04.786700Z","shell.execute_reply":"2024-11-08T03:53:06.492325Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/118 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53251bf180694c059259c4dc09c9b41c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train_data.csv:   0%|          | 0.00/656k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42a3875fcb8f40aab4d46265fcfbfc9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/494 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"715fe60d139344918d9fcdc3fe4b66ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/445 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0da4abb8da6c4d17a27bb4ea133c9abb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/49 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"399b6a94182e41b292e6fb0ef95795f5"}},"metadata":{}},{"name":"stdout","text":"Created train dataset!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"dataset['train'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T03:53:09.073496Z","iopub.execute_input":"2024-11-08T03:53:09.075225Z","iopub.status.idle":"2024-11-08T03:53:09.511765Z","shell.execute_reply.started":"2024-11-08T03:53:09.075163Z","shell.execute_reply":"2024-11-08T03:53:09.510692Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'id': 1,\n 'context': '\\nCó 1 bảng tên jidouka cần truy vấn. Bảng cần truy vấn bao gồm các cột: \\nid: số thứ tự của hàng (int);\\ninnovation_name: tên của tác phẩm cải tiến (str);\\ntask_type: Tác phẩm cải tiến đó sinh ra để làm gì? (str) (ví dụ: Xử lí database, nhập thông tin, tối ưu quy trình làm việc,...) ;\\ntool: Công cụ để thực hiện (str) (ví dụ: Python, Excel, Visual Studio Code, ...);\\ndescribe_innovation: Mô tả rõ ràng hơn mục đích của công cụ (giải thích rõ hơn cột task_type) (str)  ;\\nproduct: Output của công cụ có định dạng như thế nào (str) (ví dụ: file csv, file xlsx, ....);\\npic: Tên người phụ trách quản lí công cụ (str)  ;\\ndc: Phòng ban làm việc của người phụ trách quản lí công cụ (str) (dc1, dc2, dc3, dcd, souko,...);\\nsaved_hours: số lượng giờ mà nhờ việc áp dụng cải tiến tiết kiệm được (int);\\ncreated_at: Thời điểm công cụ này ra mắt (str) (ví dụ: 2024-10-11, 2024-10-09,...);\\ninformation: Đường link youtube tài liệu hướng dẫn sử dụng công cụ (str)\\n    ',\n 'question': 'Tôi muốn biết tên của các tác phẩm cải tiến trong bảng.',\n 'answer': 'SELECT innovation_name FROM jidouka;'}"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"### Preprocessing data","metadata":{}},{"cell_type":"code","source":"def tokenize_function(sample):\n    \"\"\"\n    Convert dataset to instructions for LLM\n    Args:\n    sample: a record from dataset include id, context, questions, sql_answer\n    \"\"\"\n    start_prompt = \"Context:\\n\"\n    middle_prompt = \"\\n\\nQuestion:\\n\"\n    end_prompt = \"\\n\\nAnswer:\\n\"\n\n    data_zip = zip(sample['context'], sample['question'])\n    prompt = [start_prompt + context + middle_prompt + question + end_prompt for context, question in data_zip]\n    sample['input_ids'] = tokenizer(prompt, padding=True, truncation=True, return_tensors=\"pt\").input_ids\n    sample['labels'] = tokenizer(sample['answer'], padding=True, truncation=True, return_tensors=\"pt\").input_ids\n\n\n    return sample","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T03:53:12.607195Z","iopub.execute_input":"2024-11-08T03:53:12.608204Z","iopub.status.idle":"2024-11-08T03:53:12.616182Z","shell.execute_reply.started":"2024-11-08T03:53:12.608160Z","shell.execute_reply":"2024-11-08T03:53:12.614774Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"tokenized_datasets = dataset.map(tokenize_function, batched=True)\ntokenized_datasets = tokenized_datasets.remove_columns(['id', 'context', 'question','answer'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T03:53:13.824707Z","iopub.execute_input":"2024-11-08T03:53:13.825423Z","iopub.status.idle":"2024-11-08T03:53:14.334744Z","shell.execute_reply.started":"2024-11-08T03:53:13.825380Z","shell.execute_reply":"2024-11-08T03:53:14.333701Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/445 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"975eab71bab14e56a91c7e77b8d5d317"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/49 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"324d60968009440f9cd07dbede7d65ff"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"tokenized_datasets['train'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T03:53:20.211308Z","iopub.execute_input":"2024-11-08T03:53:20.211755Z","iopub.status.idle":"2024-11-08T03:53:20.231155Z","shell.execute_reply.started":"2024-11-08T03:53:20.211711Z","shell.execute_reply":"2024-11-08T03:53:20.230075Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [12832,\n  11199,\n  35862,\n  1457,\n  40,\n  2206,\n  473,\n  3006,\n  342,\n  1539,\n  2647,\n  913,\n  713,\n  833,\n  35792,\n  5609,\n  913,\n  713,\n  833,\n  845,\n  825,\n  72,\n  3034,\n  35862,\n  8943,\n  35862,\n  210,\n  739,\n  487,\n  54,\n  312,\n  33,\n  3833,\n  35831,\n  35899,\n  1611,\n  15777,\n  2394,\n  35997,\n  13792,\n  35862,\n  473,\n  54,\n  643,\n  962,\n  1573,\n  772,\n  33,\n  6494,\n  35831,\n  35899,\n  4,\n  21079,\n  35997,\n  1951,\n  4701,\n  35862,\n  4476,\n  962,\n  1573,\n  772,\n  173,\n  457,\n  170,\n  180,\n  239,\n  1080,\n  35933,\n  33,\n  6494,\n  35831,\n  33,\n  35802,\n  35850,\n  2038,\n  35862,\n  5025,\n  3741,\n  35,\n  371,\n  27075,\n  35790,\n  930,\n  326,\n  345,\n  35790,\n  1229,\n  2449,\n  212,\n  498,\n  239,\n  217,\n  35790,\n  5402,\n  35831,\n  207,\n  1904,\n  468,\n  35862,\n  321,\n  1352,\n  180,\n  305,\n  219,\n  33,\n  6494,\n  35831,\n  33,\n  35802,\n  35850,\n  2038,\n  35862,\n  24044,\n  35790,\n  30441,\n  35790,\n  17770,\n  11445,\n  18782,\n  35790,\n  9255,\n  35831,\n  35899,\n  23405,\n  1177,\n  4829,\n  35997,\n  5127,\n  990,\n  2394,\n  35862,\n  5457,\n  461,\n  836,\n  2118,\n  411,\n  1036,\n  1750,\n  54,\n  171,\n  1352,\n  33,\n  6121,\n  137,\n  1470,\n  836,\n  411,\n  3034,\n  4,\n  21079,\n  35997,\n  1951,\n  4701,\n  35831,\n  33,\n  6494,\n  35831,\n  207,\n  19645,\n  8059,\n  35862,\n  9659,\n  24194,\n  54,\n  171,\n  1352,\n  71,\n  238,\n  1650,\n  187,\n  482,\n  847,\n  33,\n  6494,\n  35831,\n  33,\n  35802,\n  35850,\n  2038,\n  35862,\n  10088,\n  7,\n  34572,\n  35790,\n  10088,\n  52,\n  18338,\n  35844,\n  35790,\n  6,\n  5402,\n  35831,\n  35899,\n  20003,\n  35862,\n  2576,\n  93,\n  927,\n  1046,\n  1034,\n  3741,\n  171,\n  1352,\n  33,\n  6494,\n  35831,\n  207,\n  35,\n  35788,\n  35862,\n  1211,\n  817,\n  239,\n  217,\n  54,\n  93,\n  927,\n  1046,\n  1034,\n  3741,\n  171,\n  1352,\n  33,\n  6494,\n  35831,\n  33,\n  35818,\n  35788,\n  35839,\n  35790,\n  35,\n  35788,\n  35852,\n  35790,\n  35,\n  35788,\n  35879,\n  35790,\n  35,\n  35788,\n  35818,\n  35790,\n  905,\n  15043,\n  35790,\n  5402,\n  35831,\n  35899,\n  31716,\n  983,\n  35997,\n  35785,\n  18831,\n  35862,\n  210,\n  358,\n  823,\n  458,\n  1851,\n  217,\n  1270,\n  419,\n  1573,\n  772,\n  1282,\n  4035,\n  74,\n  33,\n  3833,\n  35831,\n  35899,\n  19398,\n  9519,\n  35997,\n  371,\n  35862,\n  2032,\n  632,\n  171,\n  1352,\n  118,\n  170,\n  1502,\n  33,\n  6494,\n  35831,\n  33,\n  35802,\n  35850,\n  2038,\n  35862,\n  60,\n  35846,\n  35852,\n  35885,\n  35834,\n  35839,\n  35846,\n  35834,\n  35839,\n  35839,\n  35790,\n  60,\n  35846,\n  35852,\n  35885,\n  35834,\n  35839,\n  35846,\n  35834,\n  35846,\n  35873,\n  35790,\n  5402,\n  35831,\n  35899,\n  1611,\n  9024,\n  2394,\n  35862,\n  397,\n  17494,\n  26925,\n  496,\n  1014,\n  1184,\n  861,\n  515,\n  419,\n  171,\n  1352,\n  33,\n  6494,\n  35831,\n  19934,\n  1363,\n  35862,\n  1556,\n  1148,\n  300,\n  473,\n  54,\n  72,\n  643,\n  962,\n  1573,\n  772,\n  80,\n  2206,\n  35792,\n  10724,\n  10302,\n  35862,\n  35783,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n 'labels': [7208,\n  35859,\n  4184,\n  35814,\n  1611,\n  15777,\n  2394,\n  35997,\n  13792,\n  16529,\n  9323,\n  3006,\n  342,\n  1539,\n  2647,\n  35899,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0]}"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"### Test model before fine-tuning","metadata":{}},{"cell_type":"code","source":"question = dataset['validation'][0]['question']\ncontext = dataset['validation'][0]['context']\nanswer = dataset['validation'][0]['answer']\n\nprompt = f\"\"\"Context:\n{context}\n\nQuestion:\n{question}\n\nAnswer:\n\"\"\"\n\ninputs = tokenizer(prompt, return_tensors='pt')\ninputs = inputs.to(device)\n\noutput = tokenizer.decode(\n    original_model.generate(\n        inputs[\"input_ids\"], \n        max_new_tokens=200,\n    )[0], \n    skip_special_tokens=True\n)\n\ndash_line = '-'.join('' for x in range(100))\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{prompt}')\nprint(dash_line)\nprint(f'BASELINE HUMAN ANSWER:\\n{answer}\\n')\nprint(dash_line)\nprint(f'MODEL GENERATION - ZERO SHOT:\\n{output}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T03:53:30.612817Z","iopub.execute_input":"2024-11-08T03:53:30.613189Z","iopub.status.idle":"2024-11-08T03:53:34.472307Z","shell.execute_reply.started":"2024-11-08T03:53:30.613151Z","shell.execute_reply":"2024-11-08T03:53:34.471178Z"}},"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\nContext:\n\nCó 1 bảng tên jidouka cần truy vấn. Bảng cần truy vấn bao gồm các cột: \nid: số thứ tự của hàng (int);\ninnovation_name: tên của tác phẩm cải tiến (str);\ntask_type: Tác phẩm cải tiến đó sinh ra để làm gì? (str) (ví dụ: Xử lí database, nhập thông tin, tối ưu quy trình làm việc,...) ;\ntool: Công cụ để thực hiện (str) (ví dụ: Python, Excel, Visual Studio Code, ...);\ndescribe_innovation: Mô tả rõ ràng hơn mục đích của công cụ (giải thích rõ hơn cột task_type) (str)  ;\nproduct: Output của công cụ có định dạng như thế nào (str) (ví dụ: file csv, file xlsx, ....);\npic: Tên người phụ trách quản lí công cụ (str)  ;\ndc: Phòng ban làm việc của người phụ trách quản lí công cụ (str) (dc1, dc2, dc3, dcd, souko,...);\nsaved_hours: số lượng giờ mà nhờ việc áp dụng cải tiến tiết kiệm được (int);\ncreated_at: Thời điểm công cụ này ra mắt (str) (ví dụ: 2024-10-11, 2024-10-09,...);\ninformation: Đường link youtube tài liệu hướng dẫn sử dụng công cụ (str)\n    \n\nQuestion:\nCông cụ nào giúp tôi tối ưu hóa công việc?\n\nAnswer:\n\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN ANSWER:\nSELECT innovation_name FROM jidouka WHERE task_type = 'Tối ưu quy trình làm việc';\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\nselect tasktype from tác_giả as t1 join tác_giả as t2 on t1.id tác_giả  t2.id tác_giả join công_ty cải tiến as t3 on t2.id công_ty cải tiến  t3.id công_ty cải tiến where t3.tên tác_giả  \"str\" and t3.tên tác_giả  \"str\"\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"to_train = True\nmodel_name = 'Biscottezi/vit5-base-finetuned-vitext2sql'\nfinetuned_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\nfinetuned_model = finetuned_model.to(device)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T03:54:18.632239Z","iopub.execute_input":"2024-11-08T03:54:18.632632Z","iopub.status.idle":"2024-11-08T03:54:19.795815Z","shell.execute_reply.started":"2024-11-08T03:54:18.632593Z","shell.execute_reply":"2024-11-08T03:54:19.794489Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(\"finetuned_model_10_epoch\")\n# finetuned_model = finetuned_model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T16:26:18.884949Z","iopub.execute_input":"2024-11-07T16:26:18.885336Z","iopub.status.idle":"2024-11-07T16:26:19.265085Z","shell.execute_reply.started":"2024-11-07T16:26:18.885274Z","shell.execute_reply":"2024-11-07T16:26:19.264168Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"%%time\n\nif to_train:\n    output_dir = f'/kaggle/working/sql-training-{str(int(time.time()))}'\n\n    training_args = TrainingArguments(\n        output_dir=output_dir,\n        learning_rate=5e-3,\n        num_train_epochs=100,\n        per_device_train_batch_size=16,     # batch size per device during training\n        per_device_eval_batch_size=16,      # batch size for evaluation\n        weight_decay=0.01,\n        logging_steps=50,\n        evaluation_strategy='steps',        # evaluation strategy to adopt during training\n        eval_steps=50,                     # number of steps between evaluation\n    )\n\n    early_stopping_callback = EarlyStoppingCallback( \n        early_stopping_patience=5\n    )\n\n    trainer = Trainer(\n        model=finetuned_model,\n        args=training_args,\n        train_dataset=tokenized_datasets['train'],\n        eval_dataset=tokenized_datasets['validation'],\n        callbacks=[early_stopping_callback]\n    )\n    \n    trainer.train()\n    \n    finetuned_model.save_pretrained(\"finetuned_model_100_epoch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T03:55:12.203321Z","iopub.execute_input":"2024-11-08T03:55:12.204058Z","iopub.status.idle":"2024-11-08T04:43:59.926754Z","shell.execute_reply.started":"2024-11-08T03:55:12.204013Z","shell.execute_reply":"2024-11-08T04:43:59.925641Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1400' max='1400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1400/1400 48:43, Epoch 100/100]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>5.875000</td>\n      <td>2.603316</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>2.395300</td>\n      <td>2.156250</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>2.188100</td>\n      <td>1.859375</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.962500</td>\n      <td>1.567921</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.775900</td>\n      <td>1.442921</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.903400</td>\n      <td>2.402105</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>2.139100</td>\n      <td>1.614796</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.837800</td>\n      <td>1.458546</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.628400</td>\n      <td>1.273756</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.826700</td>\n      <td>2.613520</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>2.251400</td>\n      <td>1.843750</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.779400</td>\n      <td>1.398756</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>1.627000</td>\n      <td>1.266263</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.570800</td>\n      <td>1.289381</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>1.494700</td>\n      <td>1.021684</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.330900</td>\n      <td>1.047513</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>1.253900</td>\n      <td>0.949139</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.197900</td>\n      <td>1.110651</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>1.399100</td>\n      <td>1.055963</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.717800</td>\n      <td>1.399394</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>1.673100</td>\n      <td>1.383769</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>1.486100</td>\n      <td>1.149713</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>1.421400</td>\n      <td>1.097736</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>1.378900</td>\n      <td>1.038106</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>1.306100</td>\n      <td>0.999043</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>1.290600</td>\n      <td>1.001594</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>1.309200</td>\n      <td>1.004305</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>1.303600</td>\n      <td>1.004305</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"CPU times: user 49min 55s, sys: 16min 33s, total: 1h 6min 28s\nWall time: 48min 47s\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(\"finetuned_model_100_epoch\")\nfinetuned_model = finetuned_model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T04:46:05.888784Z","iopub.execute_input":"2024-11-08T04:46:05.889217Z","iopub.status.idle":"2024-11-08T04:46:07.229140Z","shell.execute_reply.started":"2024-11-08T04:46:05.889174Z","shell.execute_reply":"2024-11-08T04:46:07.228047Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"question = \"Công cụ nào giúp tôi tiết kiệm thời gian khi làm việc?\"\ncontext = \"\"\"Có 1 bảng cần truy vấn. \nBảng cần truy vấn bao gồm các cột: \nid: số thứ tự của hàng (int);\ninnovation_name: tên của tác phẩm cải tiến (str);\ntask_type: Tác phẩm cải tiến đó sinh ra để làm gì? (str) (ví dụ: Xử lí database, nhập thông tin, tối ưu quy trình làm việc,...) ;\ntool: Công cụ để thực hiện (str) (ví dụ: Python, Excel, Visual Studio Code, ...);\ndescribe_innovation: Mô tả rõ ràng hơn mục đích của công cụ (giải thích rõ hơn cột task_type) (str)  ;\nproduct: Output của công cụ có định dạng như thế nào (str) (ví dụ: file csv, file xlsx, ....);\npic: Tên người phụ trách quản lí công cụ (str)  ;\ndc: Phòng ban làm việc của người phụ trách quản lí công cụ (str) (dc1, dc2, dc3, dcd, souko,...);\nsaved_hours: số lượng giờ mà nhờ việc áp dụng cải tiến tiết kiệm được (int);\ncreated_at: Thời điểm công cụ này ra mắt (str) (ví dụ: 2024-10-11, 2024-10-10,...);\ninformation: Đường link youtube tài liệu hướng dẫn sử dụng công cụ (str)\"\"\"\nanswer = \"\"\"\nSELECT innovation_name, saved_hours FROM jidouka ORDER BY saved_hours DESC LIMIT 1;\"\"\"\nprompt = f\"\"\"Context:\n{context}\n\nQuestion:\n{question}\n\nAnswer:\n\"\"\"\n\ninputs = tokenizer(prompt, return_tensors='pt')\ninputs = inputs.to(device)\n\noutput = tokenizer.decode(\n    finetuned_model.generate(\n        inputs[\"input_ids\"], \n        max_new_tokens=200,\n    )[0], \n    skip_special_tokens=True\n)\n\ndash_line = '-'.join('' for x in range(100))\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{prompt}')\nprint(dash_line)\nprint(f'BASELINE HUMAN ANSWER:\\n{answer}\\n')\nprint(dash_line)\nprint(f'FINE-TUNED MODEL - ZERO SHOT:\\n{output}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T04:47:26.436789Z","iopub.execute_input":"2024-11-08T04:47:26.437877Z","iopub.status.idle":"2024-11-08T04:47:27.158049Z","shell.execute_reply.started":"2024-11-08T04:47:26.437831Z","shell.execute_reply":"2024-11-08T04:47:27.157015Z"}},"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\nContext:\nCó 1 bảng cần truy vấn. \nBảng cần truy vấn bao gồm các cột: \nid: số thứ tự của hàng (int);\ninnovation_name: tên của tác phẩm cải tiến (str);\ntask_type: Tác phẩm cải tiến đó sinh ra để làm gì? (str) (ví dụ: Xử lí database, nhập thông tin, tối ưu quy trình làm việc,...) ;\ntool: Công cụ để thực hiện (str) (ví dụ: Python, Excel, Visual Studio Code, ...);\ndescribe_innovation: Mô tả rõ ràng hơn mục đích của công cụ (giải thích rõ hơn cột task_type) (str)  ;\nproduct: Output của công cụ có định dạng như thế nào (str) (ví dụ: file csv, file xlsx, ....);\npic: Tên người phụ trách quản lí công cụ (str)  ;\ndc: Phòng ban làm việc của người phụ trách quản lí công cụ (str) (dc1, dc2, dc3, dcd, souko,...);\nsaved_hours: số lượng giờ mà nhờ việc áp dụng cải tiến tiết kiệm được (int);\ncreated_at: Thời điểm công cụ này ra mắt (str) (ví dụ: 2024-10-11, 2024-10-10,...);\ninformation: Đường link youtube tài liệu hướng dẫn sử dụng công cụ (str)\n\nQuestion:\nCông cụ nào giúp tôi tiết kiệm thời gian khi làm việc?\n\nAnswer:\n\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN ANSWER:\n\nSELECT innovation_name, saved_hours FROM jidouka ORDER BY saved_hours DESC LIMIT 1;\n\n---------------------------------------------------------------------------------------------------\nFINE-TUNED MODEL - ZERO SHOT:\nSELECT innovation_name FROM jidouka WHERE task_type  'Tối ưu quy trình làm việc';\n","output_type":"stream"}],"execution_count":18}]}